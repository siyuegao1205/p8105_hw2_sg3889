P8105 Homework 2
================
Siyue Gao
2022-10-04

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

## Reading and Cleaning

First, read and clean the raw dataset. Only retain line, station, name,
station latitude / longitude, routes served, entry, vending, entrance
type, and ADA compliance.

``` r
transit_data = read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:vending, ada) %>% 
  mutate(
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11),
    entry = ifelse(entry == "YES", TRUE, FALSE)
    )
```

To this point, after reading in the raw dataset, I used `select`
function to make the `transit_data` retain only 20 variables, including
`line`, `station_name`, `station_latitude`, `station_longitude`, route
served (`route1` to `route11`), `entry`, `entrance_type`, `exit_only`,
`vending`, and `ada`. The resulting dataset contains 1868 rows and 20
columns. `route1` to `route7` are recognized as character by R, however,
`route8` to `route11` are recognized as numeric. As a result, I used the
`mutate` function to convert it into character variable. The `entry` of
`yes` / `no` is converted into a logical variable.

The data are not “tidy”: route served should be a single variable. In
this case, we may need to convert `route1` to `route11` from a wide to a
long format.

## Some Questions

Now I would answer some questions using these data as required in the
Homework instructions.

1.  How many distinct stations are there?

``` r
transit_data %>% 
  select(line, station_name) %>% 
  distinct() %>% 
  nrow()
## [1] 465
```

There are 465 distinct stations.

2.  How many stations are ADA compliant?

``` r
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(line, station_name) %>% 
  distinct() %>% 
  nrow()
## [1] 84
```

There are 84 stations that are ADA compliant.

3.  What proportion of station entrances / exits without vending allow
    entrance?

For this question, I first subset the dataset limited to `vending` ==
`NO`. Then, I count the `entry` variable and get the proportion.

``` r
transit_data %>% 
  filter(vending == "NO") %>% 
  count(entry) %>%
  mutate(prop = n/sum(n))
## # A tibble: 2 × 3
##   entry     n  prop
##   <lgl> <int> <dbl>
## 1 FALSE   114 0.623
## 2 TRUE     69 0.377
```

37.7% of station entrances / exits without vending allows entrance.

## Reformatting

First, convert `route` to long format by `pivot_longer()`.

``` r
transit_tidy_data = pivot_longer(
    transit_data,
    route1:route11,
    names_to = "route_num",
    names_prefix = "route",
    values_to = "route")
```

Then, we can answer some questions based on the tidy dataset.

-   How many distinct stations serve the A train?

``` r
transit_tidy_data %>% 
  filter(route == "A") %>% 
  select(line, station_name) %>% 
  distinct() %>% 
  nrow()
## [1] 60
```

There are 60 distinct stations serving the A train.

-   Of the stations that serve the A train, how many are ADA compliant?

``` r
transit_tidy_data %>% 
  filter(route == "A") %>% 
  filter(ada == TRUE) %>% 
  select(line, station_name) %>% 
  distinct() %>% 
  nrow()
## [1] 17
```

Of the stations that serve the A train, there are 17 stations that are
ADA compliant.

# Problem 2

## Reading and Cleaning

Read and clean the **Mr. Trash Wheel** sheet. The following code chunk
specifies the “Mr. Trash Wheel” sheet to be imported, and omits non-data
entries and rows that do not contain dumpster-specific data (the total
summary rows). The number of sports balls are rounded to the nearest
integer by `round()` and are converted to an integer variable afterward
by `as.interger()`.

``` r
mr_trash = 
  read_excel("data/Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             skip = 1
             ) %>% 
  janitor::clean_names() %>% 
  select(c("dumpster":"homes_powered")) %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls, digits = 0)))
```

Conduct a similar process to the **Professor Trash Wheel**. However, the
updated version dataset does not contain a column for sports balls. I
create one and relocate it at the same position as it is in `mr_trash`,
making the two datasets have the same “structure” to be combined.

``` r
pro_trash = 
  read_excel("data/Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel",
             skip = 1
             ) %>% 
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>% 
  mutate(
    sports_balls = as.integer(NA),
    year = as.character(year)
    ) %>% 
  relocate(sports_balls, .before = homes_powered)
```

## Combining

Use `bind_rows()` to combine the two trash wheel datasets together. Add
a new variable called `trash_wheel` to keep track of which Trash Wheel
is which.

``` r
mr_trash = mr_trash %>% 
  mutate(trash_wheel = "Mr. Trash Wheel")

pro_trash = pro_trash %>% 
  mutate(trash_wheel = "Professor Trash Wheel")

trash = 
  bind_rows(mr_trash, pro_trash) %>%
  select(trash_wheel, everything())
```

### Data Description

The resulting dataset contains observations on 641 trash wheels
collected by two different projects, including 547 by Mr. Trash Wheel
and 94 by Professor Trash Wheel. The data include 15 variables, and are
primarily describing the collected trash information at specific
dumpsters at different times (for Mr. Trash Wheel, from May, 2014 to
July, 2022; for Professor Trash Wheel, from January, 2017 to July,
2022). Some key variables of trash collected information are weight in
tons, volume in cubic yards, amount of different types of trash, such as
plastic bottles, polystyrene, cigarette butts, glass bottles, etc.

The total weight of trash collected by **Professor Trash Wheel** was
190.12 tons. The total number of sports balls collected by **Mr. Trash
Wheel** in 2020 was 856.

# Problem 3

## Reading and Cleaning

After reading in the pols-months.csv dataset, we would like to tidy it
by separating `mon` into `year`, `month` and `day` (replace month number
with month name using `month.name[]` and discard the `day` variable).

Note that there are some “2”s in the `prez_gop` column, for me it’s
likely to be mis-coded, after manually checking by `group_by()` and
`count()` commands. However, the `prez_dem` column seems to be correct,
with only “0” and “1”, and the total count of “1”s and “2”s in
`prez_gop` column matches perfectly with the count of “0”s in `prez_dem`
column, which is reasonable. In this case, I create a `president`
variable taking values `gop` and `dem` by `ifelse()` inside of
`mutate()`, where I use `prez_dem == 0` or not as the judging argument.

``` r
pols = read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(
    year = as.integer(year),
    month = month.name[as.numeric(month)],
    month = factor(month, levels = month.name),
    president = ifelse(prez_dem == 0, "gop", "dem")
    ) %>% 
  select(-c("day", "prez_gop", "prez_dem")) %>% 
  select(year, month, president, everything())
```

The following code chunk aims to tidy up the snp.csv by a similar
process. Note that the `year` and `month` variables are kept in the same
format and the same ascending sequence as in the `pols` dataset.

``` r
snp = read_csv("data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    date = format(as.Date(date, format = "%m/%d/%y"), "%Y-%m"),
    ) %>% 
  separate(date, into = c("year","month"), sep = "-") %>% 
  mutate(
    year = as.numeric(year),
    year = ifelse(year > 2015, year - 100, year),
    month = month.name[as.numeric(month)],
    month = factor(month, levels = month.name)
    ) %>% 
  arrange(year, month)
```

The following code chunk aims to tidy the unemployment.csv to be merged
with `pols` and `snp`. A `pivot_longer()` process will be necessary.
Note that the `year` and `month` should be in the same format as those
in the previous datasets.

``` r
unemployment = read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
    ) %>%
  mutate(
    month = str_to_title(month),
    month = month.name[match(month, month.abb)],
    month = factor(month, levels = month.name)
    )
```

## Merging

First, merge `snp` into `pols` and name the resulting dataset as
`result`.

``` r
result = right_join(
  snp,
  pols,
  by = c("year", "month")
  ) %>% 
  arrange(year, month)
```

Then, merge `unemployment` into `result` to get the final version of the
resulting dataset.

``` r
result = right_join(
  unemployment,
  result,
  by = c("year", "month")
  ) %>% 
  arrange(year, month)
```

### Data Description

The `pols` dataset contains 822 observations with 9 variables. It
describes information related to party of the president and number of
national politicians who are democratic or republican at any given time
from January, 1947 to June, 2015.

The `snp` dataset contains 787 observations with 3 variables. It
describes the closing values of the Standard & Poor’s (S&P) stock market
index at any given time from January, 1950 to July, 2015.

The `unemployment` dataset contains 816 observations with 3 variables.
It describes the percentage of unemployment at any given time from
January, 1948 to June, 2015.

The resulting dataset `result` are merged by `year` and `month`,
containing 822 observations with 11 variables. It summarizes the
information from the previous datasets in one table and gives a more
intuitive description of the potential relationship among party of the
president (`president`) / governor, closing values of S&P stock index
(`close`), and unemployment rate (`unemployment`) at the associated time
point from January, 1947 to June, 2015.
